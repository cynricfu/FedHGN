{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13fd831-b840-4c09-adda-65490e1a6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import dgl\n",
    "from dgl.data import AIFBDataset, MUTAGDataset, BGSDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5457aa8d-4119-4a51-bdfc-339b4f73df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. randomly sample triplets\n",
    "# 2. randomly sample edge types\n",
    "nc_val_size = 0.2\n",
    "settings = [3, 5, 10]  # must be larger than 2\n",
    "transform = dgl.AddReverse(copy_edata=False, sym_new_etype=True)\n",
    "save_path_prefix = Path(\"./data/\")\n",
    "random.seed(12345)\n",
    "random_state = random.getstate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd6f92-b34e-4743-b0c4-fae8e3dede2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. randomly sample triplets\n",
    "# randomly and evenly distribute all edges into (num_clients + 2) groups\n",
    "# each client exclusively own one group of edges\n",
    "# edges of one another group are shared by random k clients (1 < k < num_clients)\n",
    "# one final group is shared by all clients\n",
    "def split_by_random_edges(g, num_clients):\n",
    "    assert num_clients > 2\n",
    "\n",
    "    edges = []\n",
    "    for cetype in g.canonical_etypes:\n",
    "        edges.extend([(cetype, i) for i in range(g.num_edges(etype=cetype))])\n",
    "\n",
    "    random.shuffle(edges)\n",
    "    segment_size = len(edges) // (num_clients + 2)\n",
    "    all_client_edges = []\n",
    "    for i in range(num_clients):\n",
    "        client_edges = edges[i * segment_size: (i + 1) * segment_size] + edges[(num_clients + 1) * segment_size:]\n",
    "        all_client_edges.append(client_edges)\n",
    "    for edge in edges[num_clients * segment_size: (num_clients + 1) * segment_size]:\n",
    "        k = random.randint(2, num_clients - 1)\n",
    "        sampled_clients = random.sample(range(num_clients), k)\n",
    "        for client in sampled_clients:\n",
    "            all_client_edges[client].append(edge)\n",
    "\n",
    "    g_list = []\n",
    "    for client_edges in all_client_edges:\n",
    "        client_edges.sort()\n",
    "        eid_dict = {cetype: th.tensor([eid for _, eid in edge_iter]) for cetype, edge_iter in\n",
    "                    itertools.groupby(client_edges, lambda x: x[0])}\n",
    "        temp_g = dgl.edge_subgraph(g, eid_dict)\n",
    "        canonical_etypes = [cetype for cetype in temp_g.canonical_etypes if temp_g.num_edges(cetype) > 0]\n",
    "        g_list.append(dgl.edge_type_subgraph(temp_g, canonical_etypes))\n",
    "\n",
    "    return g_list\n",
    "\n",
    "# 2. randomly sample edge types\n",
    "# randomly and evenly distribute all etypes into (num_clients + 2) groups\n",
    "# each client exclusively own one group of etypes\n",
    "# etypes of one another group are shared by random k clients (1 < k < num_clients)\n",
    "# one final group is shared by all clients\n",
    "def split_by_random_etypes(g, num_clients):\n",
    "    assert num_clients > 2\n",
    "    assert len(g.canonical_etypes) > num_clients\n",
    "\n",
    "    canonical_etypes = g.canonical_etypes.copy()\n",
    "    random.shuffle(canonical_etypes)\n",
    "    if len(g.canonical_etypes) > num_clients + 1:\n",
    "        segment_size = len(canonical_etypes) // (num_clients + 2)\n",
    "        all_client_cetypes = []\n",
    "        for i in range(num_clients):\n",
    "            client_cetypes = canonical_etypes[i * segment_size: (i + 1) * segment_size] + canonical_etypes[\n",
    "                                                                                          (num_clients + 1) * segment_size:]\n",
    "            all_client_cetypes.append(client_cetypes)\n",
    "        for cetype in canonical_etypes[num_clients * segment_size: (num_clients + 1) * segment_size]:\n",
    "            k = random.randint(2, num_clients - 1)\n",
    "            sampled_clients = random.sample(range(num_clients), k)\n",
    "            for client in sampled_clients:\n",
    "                all_client_cetypes[client].append(cetype)\n",
    "    else:\n",
    "        # len(g.canonical_etypes) == num_clients + 1\n",
    "        all_client_cetypes = [[canonical_etypes[i], canonical_etypes[-1]] for i in range(num_clients)]\n",
    "\n",
    "    g_list = []\n",
    "    for client_cetypes in all_client_cetypes:\n",
    "        client_cetypes.sort()\n",
    "        g_list.append(dgl.compact_graphs(dgl.edge_type_subgraph(g, client_cetypes)))\n",
    "\n",
    "    return g_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa19e3-e47f-4d50-baae-22c5e173c331",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# node classification\n",
    "# AIFBDataset, MUTAGDataset, BGSDataset\n",
    "random.setstate(random_state)\n",
    "nc_datasets = [AIFBDataset, MUTAGDataset, BGSDataset]\n",
    "\n",
    "for DatasetClass in nc_datasets:\n",
    "    # load dataset\n",
    "    dataset = DatasetClass(insert_reverse=False, force_reload=True)\n",
    "    g = dataset[0]\n",
    "    target_ntype = dataset.predict_category\n",
    "    num_classes = dataset.num_classes\n",
    "    train_mask = g.nodes[target_ntype].data[\"train_mask\"]\n",
    "    # train/val split\n",
    "    train_idx = train_mask.nonzero().flatten()\n",
    "    index = list(range(len(train_idx)))\n",
    "    random.shuffle(index)\n",
    "    val_idx = train_idx[index[:round(len(index) * nc_val_size)]]\n",
    "    val_mask = th.zeros_like(train_mask)\n",
    "    val_mask[val_idx] = True\n",
    "    train_mask[val_idx] = False\n",
    "    g.nodes[target_ntype].data[\"val_mask\"] = val_mask\n",
    "\n",
    "    # centralized setting\n",
    "    g_with_rev = transform(g)  # add reverse edges\n",
    "    # save graph with num_classes\n",
    "    save_path = str(save_path_prefix / dataset.name / f\"{dataset.name}_centralized_1.bin\")\n",
    "    num_classes_info = {\"num_classes\": th.tensor([num_classes])}\n",
    "    dgl.save_graphs(save_path, [g_with_rev], num_classes_info)\n",
    "\n",
    "    for num_clients in settings:\n",
    "        # split the graph (1. random edges, 2. random etypes)\n",
    "        g_list_edges = split_by_random_edges(g, num_clients)\n",
    "        g_list_etypes = split_by_random_etypes(g, num_clients)\n",
    "        # make sure each subgraph has train/val/test nodes\n",
    "        for sub_g in g_list_edges:\n",
    "            assert \"train_mask\" in sub_g.ndata\n",
    "            assert \"val_mask\" in sub_g.ndata\n",
    "            assert \"test_mask\" in sub_g.ndata\n",
    "            assert sub_g.nodes[target_ntype].data[\"train_mask\"].any()\n",
    "            assert sub_g.nodes[target_ntype].data[\"val_mask\"].any()\n",
    "            assert sub_g.nodes[target_ntype].data[\"test_mask\"].any()\n",
    "        # add reverse edges\n",
    "        g_list_edges = [transform(sub_g) for sub_g in g_list_edges]\n",
    "        g_list_etypes = [transform(sub_g) for sub_g in g_list_etypes]\n",
    "        # save graphs with num_classes\n",
    "        save_path = str(save_path_prefix / dataset.name / f\"{dataset.name}_random-edges_{num_clients}.bin\")\n",
    "        num_classes_info = {\"num_classes\": th.tensor([num_classes] * num_clients)}\n",
    "        dgl.save_graphs(save_path, g_list_edges, num_classes_info)\n",
    "        save_path = str(save_path_prefix / dataset.name / f\"{dataset.name}_random-etypes_{num_clients}.bin\")\n",
    "        dgl.save_graphs(save_path, g_list_etypes, num_classes_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1433de34-3ede-4e2e-b794-b924a39ecda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nc_dataset_statistics(dataset_name):\n",
    "    path = Path(\"data\") / dataset_name / f\"{dataset_name}_{{}}_{{}}.bin\"\n",
    "    settings = [(\"centralized\", 1)]\n",
    "    settings.extend([(split_type, num_clients) for split_type in [\"random-edges\", \"random-etypes\"] for num_clients in [3, 5, 10]])\n",
    "    for split_type, num_clients in settings:\n",
    "        g_list, _ = dgl.load_graphs(str(path).format(split_type, num_clients))\n",
    "        target_ntype = list(g_list[0].ndata[\"train_mask\"].keys())[0]\n",
    "        num_ntypes = []\n",
    "        num_etypes = []\n",
    "        num_nodes = []\n",
    "        num_edges = []\n",
    "        num_train = []\n",
    "        num_val = []\n",
    "        num_test = []\n",
    "        for g in g_list:\n",
    "            num_ntypes.append(len(g.ntypes))\n",
    "            num_etypes.append(len(g.etypes))\n",
    "            num_nodes.append(g.num_nodes())\n",
    "            num_edges.append(sum([g.num_edges(etype=cetype) for cetype in g.canonical_etypes]))\n",
    "            num_train.append(g.ndata['train_mask'][target_ntype].sum().item())\n",
    "            num_val.append(g.ndata['val_mask'][target_ntype].sum().item())\n",
    "            num_test.append(g.ndata['test_mask'][target_ntype].sum().item())\n",
    "        print(f\"{dataset_name}_{split_type}_{num_clients}\")\n",
    "        # print(f\"num_ntypes = {np.mean(num_ntypes):.1f}$\\pm${np.std(num_ntypes):.1f}\")\n",
    "        # print(f\"num_etypes = {np.mean(num_etypes):.1f}$\\pm${np.std(num_etypes):.1f}\")\n",
    "        # print(f\"num_nodes = {np.mean(num_nodes):.1f}$\\pm${np.std(num_nodes):.1f}\")\n",
    "        # print(f\"num_edges = {np.mean(num_edges):.1f}$\\pm${np.std(num_edges):.1f}\")\n",
    "        # print(f\"num_train = {np.mean(num_train):.1f}$\\pm${np.std(num_train):.1f}\")\n",
    "        # print(f\"num_val = {np.mean(num_val):.1f}$\\pm${np.std(num_val):.1f}\")\n",
    "        # print(f\"num_test = {np.mean(num_test):.1f}$\\pm${np.std(num_test):.1f}\")\n",
    "\n",
    "        print(f\"{np.mean(num_ntypes):.1f}\")\n",
    "        print(f\"{np.mean(num_etypes):.1f}\")\n",
    "        print(f\"{np.mean(num_nodes):.1f}\")\n",
    "        print(f\"{np.mean(num_edges):.1f}\")\n",
    "        print(f\"{np.mean(num_train):.1f}\")\n",
    "        print(f\"{np.mean(num_val):.1f}\")\n",
    "        print(f\"{np.mean(num_test):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593708a-4da2-4ce0-9456-8fdc78a477c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_dataset_statistics(\"bgs-hetero\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FedHGN]",
   "language": "python",
   "name": "conda-env-FedHGN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
